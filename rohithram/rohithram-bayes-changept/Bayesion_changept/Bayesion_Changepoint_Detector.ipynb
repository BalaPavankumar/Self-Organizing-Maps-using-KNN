{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detector class for Bayesian Changepoint Detection\n",
    "\n",
    "#### Dependencies :\n",
    "* Download https://github.com/hildensia/bayesian_changepoint_detection this and run **python setup.py install** to install the bayesian changepoint detection module.\n",
    "* Install **cProfile** module using pip to connect to postgresql db\n",
    "* Install **writefile_run** using pip , which is used to save the cell in a python file automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import writefile_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use scipy logsumexp().\n"
     ]
    }
   ],
   "source": [
    "%%writefile_run bayesian_changept_detector.py\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# importing modules to run the algo\n",
    "import cProfile\n",
    "import bayesian_changepoint_detection.offline_changepoint_detection as offcd\n",
    "import bayesian_changepoint_detection.online_changepoint_detection as oncd\n",
    "from functools import partial\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run bayesian_changept_detector.py -a\n",
    "\n",
    "\n",
    "class Bayesian_Changept_Detector():\n",
    "    def __init__(self,data,assetno,is_train=False,data_col_index=0,pthres=0.5,mean_runlen = 100,Nw=10):\n",
    "        \n",
    "        '''\n",
    "        Class which is used to find Changepoints in the dataset with given algorithm parameters.\n",
    "        It has all methods related to finding anomalies to plotting those anomalies and returns the\n",
    "        data being analysed and anomaly indexes.\n",
    "        Arguments :\n",
    "        data -> dataframe which has one or two more metric columnwise\n",
    "        assetno -> assetno of the dataset\n",
    "        is_train -> By Default is False , as no training required for this algo\n",
    "        data_col_index -> column index of the metric to find changepoints on\n",
    "        pthres -> Default value :0.5 , (float) it is threshold after which a changepoint is flagged as on anomaly\n",
    "        mean_runlen -> (int) By default 100, It is the average gap between two changepoints , this comes from \n",
    "                       nitty gritty math of exponential distributions\n",
    "        Nw (samples to wait) -> (int) By default 10 is being used for optimal performance. It is the samples after which\n",
    "                                we start assigning probailities for it to be a changepoint.\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        self.algo_name = 'bayesian_change_point_detection'\n",
    "        self.algo_code = 'bcp'\n",
    "        self.algo_type = 'univariate'\n",
    "        self.istrainable = is_train\n",
    "        self.data = data\n",
    "        self.data_col_index = data_col_index\n",
    "        self.metric_name = data.columns[data_col_index]\n",
    "        self.assetno = assetno\n",
    "        self.pthres = pthres\n",
    "        self.mean_runlen = mean_runlen\n",
    "        self.Nw = Nw\n",
    "\n",
    "\n",
    "    def detect_anomalies(self):\n",
    "        \n",
    "        '''\n",
    "        Detects anomalies and returns data and anomaly indexes\n",
    "        '''\n",
    "        data = self.data\n",
    "        print(\"Shape of the dataset : \")\n",
    "        print(data.shape)\n",
    "        print(\"Overview of first five rows of dataset : \")\n",
    "    #     print(data.head())\n",
    "        ncol = self.data_col_index\n",
    "        \n",
    "#         ax = data[data.columns[ncol]].plot.hist(figsize=(9,7),bins=100)\n",
    "#         ax.set_title(\"Histogram of Dataset\")\n",
    "\n",
    "        R,maxes = self.findonchangepoint(data[data.columns[ncol]].values)\n",
    "        anom_indexes = self.plotonchangepoints(R,maxes)\n",
    "        self.anom_indexes = anom_indexes\n",
    "        return data,anom_indexes\n",
    "    \n",
    "\n",
    "    def findonchangepoint(self,data):\n",
    "        '''\n",
    "        finds the changepoints and returns the run lenth probability matrix and indexes of maximum run lengths\n",
    "        probability\n",
    "        '''\n",
    "        R, maxes = oncd.online_changepoint_detection(data, partial(oncd.constant_hazard,self.mean_runlen),\n",
    "                                                     oncd.StudentT(0.1, .01, 1, 0))\n",
    "        return R,maxes\n",
    "    \n",
    "\n",
    "    def findthreshold(self,data):\n",
    "        \n",
    "        '''\n",
    "        finds inversion points where probability is greater than mean\n",
    "        Returns -> list of inversion points\n",
    "        '''\n",
    "        mu = np.mean(data)\n",
    "        inv_pt = []\n",
    "        for i in range(len(data)-1):\n",
    "            if((data[i+1]>mu and data[i]<=mu) or (data[i+1]<mu and data[i]>=mu)):\n",
    "                inv_pt.append(i)\n",
    "\n",
    "        return inv_pt    \n",
    "    \n",
    "\n",
    "    def plotonchangepoints(self,R,maxes,nrow=None):\n",
    "        '''\n",
    "        plots the original data and anomaly indexes as vertical line\n",
    "        and plots run length distribution and probability score for each possible run length\n",
    "        '''\n",
    "        fig,(ax1,ax3) = plt.subplots(2,figsize=[18, 16])\n",
    "        ncol = self.data_col_index\n",
    "        data = self.data\n",
    "        Nw = self.Nw\n",
    "        pthres = self.pthres\n",
    "        \n",
    "        ltext = 'Column : '+str(ncol+1)+' data with threshold probab = '+ str(pthres)\n",
    "\n",
    "        ax1.set_title(data.columns[ncol])\n",
    "\n",
    "        cp_probs = np.array(R[Nw,Nw:-1][1:-2])\n",
    "\n",
    "        inversion_pts = self.findthreshold(cp_probs)\n",
    "\n",
    "        max_indexes = []\n",
    "        for i in range(len(inversion_pts)-1):\n",
    "            max_indexes.append(inversion_pts[i]+np.argmax(cp_probs[inversion_pts[i]:inversion_pts[i+1]+1]))\n",
    "\n",
    "        cp_mapped_probs = pd.Series(cp_probs[max_indexes],index=max_indexes)\n",
    "        anom_indexes = cp_mapped_probs.index[(np.where(cp_mapped_probs.values>pthres)[0])]\n",
    "\n",
    "        if(nrow==None):\n",
    "            ax1.plot(data.values[:,ncol],label=ltext)\n",
    "        else:\n",
    "            ax1.plot(data.values[:nrow,ncol],label=ltext)\n",
    "\n",
    "        ax1.legend()\n",
    "\n",
    "        [ax1.axvline(x=a,color='r') for a in anom_indexes]\n",
    "\n",
    "#         sparsity = 5  # only plot every fifth data for faster display\n",
    "#         ax2.pcolor(np.array(range(0, len(R[:,0]), sparsity)), \n",
    "#                   np.array(range(0, len(R[:,0]), sparsity)), \n",
    "#                   -np.log(R[0:-1:sparsity, 0:-1:sparsity]), \n",
    "#                   cmap=cm.Greys, vmin=0, vmax=30,label=\"Distribution of Run length\")\n",
    "#         ax2.legend()\n",
    "\n",
    "        ax3.plot(cp_probs)\n",
    "\n",
    "        ax3.set_title('Change points with Probability')\n",
    "\n",
    "        plt.show()\n",
    "        print(\"\\n No of Anomalies detected = %g\"%(len(anom_indexes)))\n",
    "\n",
    "        return anom_indexes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
