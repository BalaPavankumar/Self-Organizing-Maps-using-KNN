{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing Self organising maps using KNN anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohithram/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "#importing the dependencies\n",
    "from anomaly_detectors.som_knn_detector import som_knn_wrapper as som_wrapper\n",
    "from anomaly_detectors.utils import reader_helper\n",
    "from anomaly_detectors.utils import csv_prep_for_reader as csv_helper\n",
    "from anomaly_detectors.reader_writer import db_properties as db_properties\n",
    "from anomaly_detectors.reader_writer import writer_configs as writer_configs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Arguments for reader module to get data from opentsdb\n",
    "This is included for now just for testing, later the main function will take json as direct input\n",
    "'''\n",
    "\n",
    "assetno = ['TSFAD_A1']\n",
    "con = '52.224.236.31:4242'\n",
    "src_type =  'opentsdb'\n",
    "\n",
    "param=['ec2_cpu_utilization_5f5533', 'rds_cpu_utilization_cc0c53']\n",
    "from_timestamp=1392388200\n",
    "to_timestamp=1393597320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader_kwargs= lambda:{\n",
    "            'assetno':['TSFAD_A1'],\n",
    "            'from_timestamp':from_timestamp,\n",
    "            'to_timestamp':to_timestamp,\n",
    "            'con':con,\n",
    "            'para_list':param,\n",
    "            'source_type':src_type,\n",
    "            'table_name':'',\n",
    "            'qry_str':'',\n",
    "            'impute_fill_method':'forward',\n",
    "            'down_sampling_method':None,\n",
    "            'down_sampling_window':None,\n",
    "            'freq':None,\n",
    "            'resample_fill_method':None,\n",
    "            'to_resample':None,\n",
    "            'to_impute':True,\n",
    "}\n",
    "\n",
    "model_input_args = lambda :{\n",
    "    'network_shape':(8,8),\n",
    "    'input_feature_size':None,\n",
    "    'time_constant':None,\n",
    "    'minNumPerBmu':2,\n",
    "    'no_of_neighbours':3,\n",
    "    'init_radius':0.4,\n",
    "    'init_learning_rate':0.01,\n",
    "    'N':100,    \n",
    "    'diff_order':1\n",
    "}\n",
    "\n",
    "training_args = lambda:{\n",
    "            'is_train':True,\n",
    "            'epochs':5,\n",
    "            'batch_size':4,\n",
    "            'to_plot':True,\n",
    "            'test_frac':0.2\n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "eval_args = lambda: {\n",
    "    'model_path':'',\n",
    "    'to_plot':True,\n",
    "    'anom_thres':3.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = list(model_input_args().keys())+list(training_args().keys())+list(eval_args().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['network_shape',\n",
       " 'input_feature_size',\n",
       " 'time_constant',\n",
       " 'minNumPerBmu',\n",
       " 'no_of_neighbours',\n",
       " 'init_radius',\n",
       " 'init_learning_rate',\n",
       " 'N',\n",
       " 'diff_order',\n",
       " 'is_train',\n",
       " 'epochs',\n",
       " 'batch_size',\n",
       " 'to_plot',\n",
       " 'test_frac',\n",
       " 'model_path',\n",
       " 'to_plot',\n",
       " 'anom_thres']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for modes :\n",
    "#### Testing three different modes of the program\n",
    "* First training and for testing three different modes are tested and the output is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kwargs():\n",
    "    return model_input_args(),training_args(),eval_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://52.224.236.31:4242/api/query?start=1392388200&end=1393597320&ms=true&m=max:none:ec2_cpu_utilization_5f5533{AssetNo=TSFAD_A1}\n",
      "\n",
      "Testing mode option : detect only\n",
      "\n",
      "Data reader initialised \n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-26768d43fdcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtraining_args1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'to_plot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msom_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_input_args1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtraining_args1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0meval_args1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massetno\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#     json_data = reader_helper.read(reader_kwargs1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0meval_args1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'to_plot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'models'"
     ]
    }
   ],
   "source": [
    "reader_kwargs1= reader_kwargs()\n",
    "json_data = reader_helper.read(reader_kwargs=reader_kwargs1)\n",
    "model_input_args1,training_args1,eval_args1 = get_kwargs()\n",
    "training_args1['to_plot'] = False\n",
    "\n",
    "for i in range(3):\n",
    "    mode = som_wrapper.mode_options[i]\n",
    "    print(\"\\nTesting mode option : {}\\n\".format(mode))\n",
    "    training_args1['to_plot']=False\n",
    "    train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "    eval_args1['model_path'] = train_res['models'][0][assetno[0]]\n",
    "#     json_data = reader_helper.read(reader_kwargs1)\n",
    "    eval_args1['to_plot']=False\n",
    "    test_res = som_wrapper.evaluate(**eval_args1,json_data=json_data,mode=som_wrapper.mode_options[i])\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 : \n",
    "#### Testing with parameters being empty quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_kwargs1= reader_kwargs()\n",
    "json_data = reader_helper.read(reader_kwargs=reader_kwargs1)\n",
    "model_input_args1,training_args1,eval_args1 = get_kwargs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on model_input_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(model_input_args1.keys()):\n",
    "    print(\"\\nGiving {} parameter : ''\\n\".format(key))\n",
    "    model_input_args1 = model_input_args()\n",
    "    model_input_args1[key] = ''\n",
    "    training_args1['to_plot']=False\n",
    "    train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "    print(train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_args1 = model_input_args()\n",
    "\n",
    "for key in list(training_args().keys()):\n",
    "    training_args1 = training_args()\n",
    "    training_args1[key] = ''\n",
    "#     eval_args1['to_plot']=False\n",
    "    training_args1['to_plot']=False\n",
    "    train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "    print(train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on evaluation args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_args1 = training_args()\n",
    "model_input_args1 = model_input_args()\n",
    "training_args1['to_plot']=False\n",
    "train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "print(train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in list(eval_args().keys()):\n",
    "    eval_args1 = eval_args()\n",
    "    eval_args1['model_path'] = train_res['models'][0][assetno[0]]\n",
    "    eval_args1[key] = ''\n",
    "#     json_data = reader_helper.read(reader_kwargs1)\n",
    "    eval_args1['to_plot']=False\n",
    "    test_res = som_wrapper.evaluate(**eval_args1,json_data=json_data)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2 :\n",
    "#### Testing missing parameters : \n",
    "* Since only model path is required arg, it doesn't throw any error when we don't pass other evalution args since they are optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model input args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(model_input_args1.keys()):\n",
    "    print(\"\\nGiving {} parameter : ''\\n\".format(key))\n",
    "    model_input_args1 = model_input_args()\n",
    "    del model_input_args1[key]\n",
    "    training_args1['to_plot']=False\n",
    "    train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "    print(train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(training_args1.keys()):\n",
    "    print(\"\\nGiving {} parameter : ''\\n\".format(key))\n",
    "    model_input_args1 = model_input_args()\n",
    "    del training_args1[key]\n",
    "#     training_args1['to_plot']=False\n",
    "    train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "    print(train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(eval_args().keys()):\n",
    "    eval_args1 = eval_args()\n",
    "    del eval_args1[key]\n",
    "    eval_args1['model_path'] = train_res['models'][0][assetno[0]]\n",
    "\n",
    "#     json_data = reader_helper.read(reader_kwargs1)\n",
    "    eval_args1['to_plot']=False\n",
    "    test_res = som_wrapper.evaluate(**eval_args1,json_data=json_data)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3:\n",
    "#### Testing parameter type mismatch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mismatched params arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vals = {'batch_size': 4.5,\n",
    "             'epochs': 5.5,\n",
    "             'is_train': 'True',\n",
    "             'test_frac': 3.0,\n",
    "             'to_plot': 'True'}\n",
    "\n",
    "model_vals = {'N': '100',\n",
    "             'diff_order': 1.4,\n",
    "             'init_learning_rate': 1,\n",
    "             'init_radius': 'f',\n",
    "             'input_feature_size': 'ff',\n",
    "             'minNumPerBmu': 2,\n",
    "             'network_shape': ('8', 8),\n",
    "             'no_of_neighbours': 34.4,\n",
    "             'time_constant': 'None'}\n",
    "\n",
    "eval_vals = {\n",
    "            'model_path':34,\n",
    "            'to_plot':'True',\n",
    "            'anom_thres':4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Testing training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,key in enumerate(list(training_args().keys())):\n",
    "    print(\"\\nGiving {} parameter : {}\\n\".format(key,train_vals[key]))\n",
    "    model_input_args1 = model_input_args()\n",
    "    training_args1 = training_args()\n",
    "    training_args1[key] = train_vals[key]\n",
    "    train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "    print(train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Testing model input args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,key in enumerate(list(model_input_args().keys())):\n",
    "    print(\"\\nGiving {} parameter : {}\\n\".format(key,model_vals[key]))\n",
    "    training_args1 = training_args()\n",
    "    model_input_args1 = model_input_args()\n",
    "    model_input_args1[key] = model_vals[key]\n",
    "    train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "    print(train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing eval args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args1 = training_args()\n",
    "model_input_args1 = model_input_args()\n",
    "training_args1['to_plot'] = False\n",
    "\n",
    "train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(eval_args().keys()):\n",
    "    eval_args1 = eval_args()\n",
    "    eval_args1[key] = eval_vals[key]\n",
    "\n",
    "    test_res = som_wrapper.evaluate(**eval_args1,json_data=json_data)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Defined Test Case:\n",
    "#### Testing the data missing case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_kwargs1 = reader_kwargs()\n",
    "reader_kwargs1['from_timestamp'] = int(2**40)\n",
    "\n",
    "json_data = reader_helper.read(reader_kwargs=reader_kwargs1)\n",
    "\n",
    "model_input_args1 = model_input_args()\n",
    "training_args1 = training_args()\n",
    "training_args1['to_plot']=False\n",
    "train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "print(train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6:\n",
    "#### Testing Asset Timeline Logging :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 7:\n",
    "#### Testing the response from program to follow agreed upon template :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader_kwargs1 = csv_helper.get_csv_kwargs(infile='../../dataset/lstm_train_data_201B.csv',\n",
    "                                          filename='lstm_train_data_201B.csv',has_time=False)\n",
    "\n",
    "json_data = reader_helper.read(reader_kwargs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args1 = training_args()\n",
    "model_input_args1 = model_input_args()\n",
    "training_args1['to_plot']=True\n",
    "\n",
    "train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "\n",
    "eval_args1 = eval_args()\n",
    "print(train_res)\n",
    "eval_args1['model_path'] = train_res['models'][0][assetno[0]]\n",
    "test_res = som_wrapper.evaluate(**eval_args1,json_data=json_data)\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 8:\n",
    "#### Testing No Data exception :\n",
    "* To get empty dataframe we set from and to timestamp to be not in range of the timestamps in dataset analysed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 9:\n",
    "#### Testing Database connectivity  exception :\n",
    "* To test this we edit the db properties and run the algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer_configs.table_name = 'f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_properties.db_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We change the db name and we expect a database error as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_properties.db_connection['dbname'] = 'eg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we try to change the password of db properties and observe the exception handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_properties.db_connection['password']='fef'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run db_properties.py\n",
    "\n",
    "db_connection = {'dbname': 'Cerebra',\n",
    " 'host': '127.0.0.1',\n",
    " 'password': 'givemeachance',\n",
    " 'port': '5432',\n",
    " 'user': 'postgres'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we change the table name in which we are writing, and we observe that relation doesn't exist as seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer_configs.table_name = 'ffee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer_configs.table_name = 'public.log_asset_timeline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 10:\n",
    "#### Testing random exceptions :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 11:\n",
    "#### Testing High Performance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reader_kwargs1= csv_helper.get_csv_kwargs(infile='../../dataset/bearings.csv',filename='bearings.csv',has_time=False)\n",
    "json_data = reader_helper.read(reader_kwargs=reader_kwargs1)\n",
    "model_input_args1,training_args1,eval_args1 = get_kwargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "training_args1['to_plot']=False\n",
    "training_args1['epochs']= 10\n",
    "training_args1['batch_size'] = 32\n",
    "train_res = json.loads(som_wrapper.train(**{**model_input_args1,**training_args1},json_data=json_data))\n",
    "\n",
    "eval_args1['anom_thres'] = 1\n",
    "eval_args1['model_path'] = train_res['models'][0][assetno[0]]\n",
    "eval_args1['to_plot']=False\n",
    "test_res = som_wrapper.evaluate(**eval_args1,json_data=json_data,mode=som_wrapper.mode_options[1])\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "* Hence we observe that **Bayesian Changepoint Detection** works well only on level shifts or variational shift datasets over outlier or surge,sag datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
