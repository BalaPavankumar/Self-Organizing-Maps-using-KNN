{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Self Organizing Maps using KNN for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import writefile_run as writefile_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../../anomaly_detectors/som_knn_detector/som_knn_module.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run $filename\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#torch libraries\n",
    "import torch\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run $filename -a\n",
    "\n",
    "\n",
    "class Som_model():\n",
    "    '''\n",
    "    It's a class for SOM_KNN model\n",
    "    Arguments : \n",
    "    Takes all model related arguments whose descriptions are already given in the wrapper function\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,som_shape,input_feature_size,time_constant,n_iterations,\n",
    "                 minNumPerBmu=1,no_of_neighbors=3,initial_radius=1,initial_learning_rate=0.4,diff_order=1):\n",
    "        \n",
    "        self.shape = som_shape\n",
    "        self.weight_dim = self.shape.__len__()\n",
    "        self.feature_size = input_feature_size\n",
    "        self.time_constant = time_constant\n",
    "        self.initial_radius = initial_radius\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.weights = torch.rand((*self.shape,self.feature_size),dtype=torch.float64)\n",
    "        self.bmu_counts = torch.zeros((*self.shape),dtype=torch.int32)\n",
    "        self.n_iterations = n_iterations\n",
    "        self.neuron_locations = self.neuron_locations(*self.shape)\n",
    "        self.minNumPerBmu = minNumPerBmu\n",
    "        self.no_of_neighbors = no_of_neighbors\n",
    "        self.diff_order = diff_order\n",
    "        \n",
    "    def findBMU(self,x_batch):\n",
    "        \n",
    "        \"\"\"\n",
    "         Find the best matching unit for a specific batch of samples\n",
    "        :param x_batch: The data points for which the best matching unit should be found.\n",
    "        :type x_batch: numpy.ndarray\n",
    "        :return: numpy.ndarray with index\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = len(x_batch)\n",
    "        bmu_indexes = np.zeros((batch_size,2),dtype=int)\n",
    "        for i in range(batch_size):\n",
    "            bmu_dists = np.square(self.weights.numpy()-x_batch[i].numpy()).sum(axis=-1)\n",
    "            arg_min_ind = np.argmin(bmu_dists)\n",
    "            bmu_indexes[i] = np.unravel_index(arg_min_ind,bmu_dists.shape)\n",
    "\n",
    "            \n",
    "            self.bmu_counts[np.unravel_index(arg_min_ind,bmu_dists.shape)] +=1\n",
    "\n",
    "        return bmu_indexes\n",
    "    \n",
    "    \n",
    "    def fit(self,train_batch,curr_batch_iter):\n",
    "        \n",
    "        \"\"\"Train the SOM to a specific dataset.\n",
    "        :param train_batch: The complete training dataset\n",
    "        :type train_batch: 2d ndarray\n",
    "        :param num_iterations: The number of iterations used for training\n",
    "        :type num_iterations: int\n",
    "        :return: a reference to the object\n",
    "        \"\"\"\n",
    "        \n",
    "        #finding coordinates of bMU's for training batch of inputs\n",
    "        bmu_indexes = self.findBMU(train_batch)\n",
    "        \n",
    "        #calculating current iteration number within samples of each batch\n",
    "        curr_iter = np.array([curr_batch_iter+i for i in range(len(train_batch))])\n",
    "        \n",
    "        # Update the parameters to let them decay to 0\n",
    "               \n",
    "        r_batch = self.decay_radius((curr_iter))\n",
    "        l_batch = self.decay_learning_rate(curr_iter)\n",
    "        \n",
    "        #update weights\n",
    "        self.update_weights(train_batch, bmu_indexes, r_batch, l_batch)\n",
    "        #removing the contribution from noisy data by eliminating neurons with lesser BMU hits\n",
    "        self.allowed_nodes = self.weights[self.bmu_counts >= self.minNumPerBmu]\n",
    "\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def evaluate(self,evaluationData):\n",
    "        \"\"\"\n",
    "        This function maps the evaluation data to the previously fitted network. It calculates the anomaly measure\n",
    "        based on the distance between the observation and the K-NN nodes of this observation.\n",
    "        :param evaluationData: Numpy array of the data to be evaluated\n",
    "        :return: 1D-array with for each observation an anomaly measure\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.allowed_nodes\n",
    "            assert self.allowed_nodes.shape[0] > 1\n",
    "        except NameError:\n",
    "            raise Exception(\"Make sure the method fit is called before evaluating data.\")\n",
    "        except AssertionError:\n",
    "            raise Exception(\"There are no nodes satisfying the minimum criterium, algorithm cannot proceed.\")\n",
    "        else:\n",
    "            classifier = NearestNeighbors(n_neighbors=self.no_of_neighbors)\n",
    "            classifier.fit(self.allowed_nodes)\n",
    "            dist, _ = classifier.kneighbors(evaluationData)\n",
    "        return dist.mean(axis=1)\n",
    "    \n",
    "    \n",
    "    def neuron_locations(self,m,n):\n",
    "        '''\n",
    "        Function to create locations of neurons in a 2D matrix, for example M[i,j] = [i,j]\n",
    "        Vectorised way to create this matrix\n",
    "        '''\n",
    "        r0 = np.arange(m) # Or r0,r1 = np.ogrid[:m,:n], out[:,:,0] = r0\n",
    "        r1 = np.arange(n)\n",
    "        out = np.empty((m,n,2),dtype=int)\n",
    "        out[:,:,0] = r0[:,None]\n",
    "        out[:,:,1] = r1\n",
    "        return out\n",
    "\n",
    "    def decay_radius(self,i):\n",
    "\n",
    "        return self.initial_radius * np.exp(-(1*i)/self.time_constant)\n",
    "\n",
    "    \n",
    "    def decay_learning_rate(self, i):\n",
    "        return self.initial_learning_rate * np.exp(-(1*i)/self.n_iterations)\n",
    "\n",
    "    \n",
    "    def calculate_influence(self,distance, radius):\n",
    "        '''\n",
    "        Calculate the influence of the neurons surrounding the BMU, so that it updates the weights\n",
    "        accordingly. Basically farthest neuron from the bMU will have least influence\n",
    "        '''\n",
    "        return np.exp(-distance / (2* (radius**2)))\n",
    "\n",
    "    \n",
    "    def update_weights(self,train_batch, bmu_indexes,radius,learning_speed):\n",
    "        \n",
    "        '''\n",
    "        # now we know the BMU, update its weight vector to move closer to input\n",
    "        # and move its neighbours in 2-D space closer\n",
    "        # by a factor proportional to their 2-D distance from the BMU\n",
    "        '''\n",
    "        \n",
    "        batch_size = len(train_batch)\n",
    "        \n",
    "        #print(\"BMU Index for batch {}\".format(bmu_idx))\n",
    "        network_indexes = self.neuron_locations\n",
    "        network_indexes = np.stack([network_indexes for i in range(batch_size)],axis=0)\n",
    "#         print(\"Network shape {}\".format(network_indexes.shape))\n",
    "\n",
    "        bmu_indexes = bmu_indexes.reshape(batch_size,1,1,2)\n",
    "        learning_speed = learning_speed.reshape(batch_size,1,1,1)\n",
    "        \n",
    "        w_dists_coordinates = (np.square(network_indexes - bmu_indexes))\n",
    "        \n",
    "        w_dists = (w_dists_coordinates[:,:,:,0]+w_dists_coordinates[:,:,:,1])\n",
    "\n",
    "#         print(\"Shape of distance of neurons from bmu {}\".format(w_dists.shape))\n",
    "\n",
    "        bool_index = np.array([(w_dists[i]<=r2) for i,r2 in enumerate(radius**2)])\n",
    "        \n",
    "        influence = np.array([self.calculate_influence(w_dists[i][bool_index[i]],radius[i]) \n",
    "                              for i in range((batch_size))])\n",
    "        \n",
    "        influence_neurons = np.zeros(w_dists.shape)\n",
    "#         print(influence.shape)\n",
    "        influence = influence.reshape(-1,)\n",
    "#         print(influence)\n",
    "        try:\n",
    "            influence_neurons[bool_index] = influence\n",
    "            influential_neurons = np.stack([influence_neurons for i in range(self.feature_size)],axis=-1)\n",
    "\n",
    "    #         print(\"Influtential neurons shape {}\".format(influential_neurons.shape))\n",
    "\n",
    "            learningMatrix = np.array([-torch.add(self.weights,-1*(train_batch[k])).numpy() for k in range(batch_size)])\n",
    "\n",
    "    #         print(\"Learning matrix shape {}\".format(learningMatrix.shape))\n",
    "\n",
    "    #         scaledLearningMatrix = np.zeros((batch_size,*weights.shape))\n",
    "            scaledLearningMatrix = learning_speed * (influential_neurons * learningMatrix)\n",
    "\n",
    "    #         print(\"Scaled lmatrix {}\".format(scaledLearningMatrix.shape))\n",
    "\n",
    "            [torch.add(self.weights,torch.from_numpy(scaledLearningMatrix)[k],out=self.weights) for k in range(batch_size)]\n",
    "        except:\n",
    "            return\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
